{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom fancyimpute import KNN, NuclearNormMinimization, SoftImpute, IterativeImputer, BiScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.svm import LinearSVC\nimport math\nimport regex as re",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e15e890f728e76d71b1790f3fd0457301a884a55"
      },
      "cell_type": "code",
      "source": "def sex_to_binary(x):\n    if x == \"male\":\n        x = 0\n    elif x == \"female\":\n        x = 1\n    else:\n        x = 2\n    return x\n\ndef zonecabin(x):\n    try:\n        room = re.findall('\\d+', x )\n        return int(room[0])\n    except:\n        pass\n\n'''def zonecabin(x):\n    if x == \"NaN\":\n        return x\n    cabin = int(str(x)[1:2])\n    if cabin>0 & cabin<50:\n        return 0\n    elif cabin>=50 & cabin<100:\n        return 1\n    else:\n        return 2'''\n\ndef emb_to_int(x):\n    if x == \"S\":\n        x = 0\n    elif x == \"C\":\n        x = 1\n    elif  x == \"Q\":\n        x = 2\n    return x\n\ndef lastname(x):\n    lastname = x.split(\",\")[0]\n    return lastname\n\n'''def famsize(data):\n    famsize = []\n    for i in data['lastname']:\n        famsize.append(len(data[data['lastname'] == i]))\n    return famsize'''\n\ndef floorcabin(x):\n    cabin = str(x)[0]\n    if cabin == 'A':\n        zonecabin = 7\n    elif cabin == 'B':\n        zonecabin = 6\n    elif cabin == 'C':\n        zonecabin = 5\n    elif cabin == 'D':\n        zonecabin = 4\n    elif cabin == 'E':\n        zonecabin = 3\n    elif cabin == 'F':\n        zonecabin = 2\n    elif cabin == 'G':\n        zonecabin = 1\n    elif cabin == 'T':\n        zonecabin = 0\n    else:\n        zonecabin = float('nan')\n    return zonecabin",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "train_data = pd.read_csv(\"../input/train.csv\")\ntrain_data[\"Sex\"] = train_data.Sex.apply(sex_to_binary)\ntrain_data[\"Embarked\"] = train_data.Embarked.apply(emb_to_int)\ntrain_data['lastname'] = train_data.Name.apply(lastname)\ntrain_data['famsize'] = train_data['SibSp'] + train_data['Parch'] + 1\ntrain_data['floorcabine'] = train_data.Cabin.apply(floorcabin)\ntrain_data['Zonecabine'] = train_data.Cabin.apply(zonecabin)\n#train_data[\"Age\"] = train_data[\"Age\"].fillna(train_data[\"Age\"].median())\n#train_data[\"Embarked\"] = train_data[\"Embarked\"].fillna(train_data[\"Embarked\"].median())\nx_train = train_data[['Pclass','Embarked','Fare','Parch','SibSp','Age','famsize','Sex','Zonecabine','floorcabine']]\ny_train = train_data[['Survived']]\nx_train_complete = IterativeImputer().fit_transform(x_train)\n#x_train_complete[:,-1] = np.round(x_train_complete[:,-1])\nx_train['floorcabine'] = x_train_complete[:,-1]\nx_train['Zonecabine'] = x_train_complete[:,-2]\nx_train[\"Age\"] =  x_train_complete[:,5]\nx_train[\"Embarked\"] =  x_train_complete[:,1]\nx_train['Survived'] = train_data[['Survived']]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ac8e2570188208acb9294819227c73bdddecd2a9",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "del(x_train['floorcabine'])\ndel(x_train['Zonecabine'])\nfigure = plt.figure(figsize=(9,8))\ncorr = x_train.corr().abs()\nsns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)\ndel(x_train['Survived'])\ncorr",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "79de4541c7df17682a53024c971ff21015146098"
      },
      "cell_type": "code",
      "source": "from sklearn import model_selection\nfrom sklearn.feature_selection import RFECV\nfrom sklearn import feature_selection\n\nclf = RandomForestClassifier(n_estimators=1000, max_depth=10,random_state=0,max_features='auto',min_samples_split=5)\nclf.fit(x_train[:int((0.8*len(x_train)))], y_train[:int((0.8*len(x_train)))].values.ravel())\nprint(clf.feature_importances_)\npred = clf.predict(x_train[int((0.8*len(x_train))):])\naccuracy_score(pred,y_train[int((0.8*len(x_train))):])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7a7672a710df719c6957cc2cce942bc27c694766"
      },
      "cell_type": "code",
      "source": "#tune hyper-parameters: http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\nparam_grid = {'n_estimators': [1000],\n              'criterion': ['gini', 'entropy'],  #scoring methodology; two supported formulas for calculating information gain - default is gini\n              #'splitter': ['best', 'random'], #splitting methodology; two supported strategies - default is best\n              'max_depth': [4,6,8,10,None], #max depth tree can grow; default is none\n              'min_samples_split': [2,5,10,.03,.05], #minimum subset size BEFORE new split (fraction is % of total); default is 2\n              #'min_samples_leaf': [1,5,10,.03,.05], #minimum subset size AFTER new split split (fraction is % of total); default is 1\n              'max_features': [None, 'auto'], #max features to consider when performing split; default none or all\n              'random_state': [0] #seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\n             }\n\ntune_model = model_selection.GridSearchCV(RandomForestClassifier(), param_grid=param_grid, scoring = 'roc_auc', cv = 3)\ntune_model.fit(x_train, y_train.values.ravel())\n\nprint(' RandomF Parameters: ', tune_model.best_params_)\nprint(\" RandomF Training w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100)) \nprint(\" RandomF Test w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\nprint(\" RandomF Test w/bin score 3*std: +/- {:.2f}\". format(tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))\nprint('-'*10)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}